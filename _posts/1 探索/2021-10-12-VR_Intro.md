---
layout: post
title: VR Intro
categories: VR
---

> From [聊一聊VR虚拟现实(二十一)](https://zhuanlan.zhihu.com/p/358555105) [聊一聊VR虚拟现实(十三)](https://zhuanlan.zhihu.com/p/101307076)



### 当前模型

以VR教育为例通过三个方面概述VR普及的制约因素。

##### 硬件
- **设备重量**：未来**小型化技术**成熟，**分体式 6dof** VR眼镜有望降低到100克以内的重量，佩戴体验极大提升。  
- **FOV**：VR一体机视场角目前主流是100度左右（PC头显有达到130度的，但不便长期佩戴），比**理想的120度视场角**有差距，会有**望远镜效应**。  
- **设备算力**：需要进一步提升，现在一体机离PC的**渲染能力**5年左右差距，或通过**云渲染**实现算力。  

##### 软硬件
- **计算机视觉**：**表情检测技术**还停留在实验室阶段（但**眼动检测**已用在很多B端场景）。预计未来一两年在C端落地。  
- **交互**：目前主流使用**手柄**。未来需要**裸手输入**（已实现），**力反馈**（技能培训）功能的**手套**（有产品，但不普及）。  

##### 软件
- **内容**：**数字孪生**。现实中有无数培训内容，如果要全面虚拟化，需要大量工程技术人员投入把现实内容**复刻**到VR中去。可能，未来实体产品出厂时会对外**提供标准3D模型**供培训公司使用。这个市场是巨大的。  



### 未来模型

**Hard** GPU-Cloud-Docker-5G-GaaS-IoTOS→ **VR** ←DCC-Tools-Platform-DT-CV-ML **Soft**

#### 设备端


##### 主显示设备

> 参考记录模块：[Graphic](https://metal-j.github.io/graphic/2021/07/20/Rendering_equation.html)

- **多平台协同操作**的 **平滑衔接**的 **接入云**的 **移动设备**的 **微内核操作系统**。  
- 当引擎渲染出画面后，**反畸变、合成、位置预测**等过程到屏幕上。计算机图形学和操作系统相关知识。  
- 为进一步提升渲染效率，还需引入**注视点渲染**技术。基于**深度学习**的注视点渲染图的细节恢复。通过固定注视点渲染，可以达到**视网膜屏效果**。  
- 为解决**VAC（辐辏冲突）**问题，未来还要引入**光场显示技术**。计算机图形学相关知识。  

##### 定位设备

> 参考记录模块：[Interactive](https://metal-j.github.io/interactive/2021/10/13/Interactive_Intro.html)

- **外置激光发射器定位**（Lighthouse，由Valve公司研制，HTC-vive）：通过计算头盔和手柄接收到激光信号的时间差，推导出设备的空间坐标。特点：速度快，位置准。缺点：成本高。
- **外置视觉定位** 通过外部放置摄像头，拍摄头盔/手柄上的光点，来推算出设备的位置，Oculus Rift（红外线）和 PSVR（可见光）都是使用这种方式。想要准确高效地检测出光标点，就需要**图像处理、计算机视觉**的知识。
- **内置视觉定位**（InsideOut定位）通过头盔上的摄像头拍摄画面的变化，来估计头盔运动。微软WMR、Quest使用的是这种方式。优势是不需要额外架设设备。但是定位精度上比激光定位要差一些。为了能根据画面来推断相机的运动，也需要**计算机视觉**相关知识。InsideOut 头部定位对应的手部定位稍微复杂点，它又分为电磁手柄定位、超声手柄定位和视觉手柄定位三种方式。前两种一般是硬件直接给出定位坐标，最后一种仍然是基于**计算机视觉**，只不过摄像头从外置摄像头换成了头盔上的摄像头。

##### 识别设备

- **手势识别、身体姿态识别、表情识别、眼动追踪**。手势识别有两个技术路线：一是需要佩戴手套，靠硬件来识别，二是基于**计算机视觉**来识别。前者优势是精准，后者的优势是使用简便。眼动追踪则主要是 **计算机视觉** 方案，现在也有眼部肌电信号来进行眼动追踪的方法，但是只存在于实验室里。最后，表情识别只能靠 **计算机视觉** 来做。以上提到的所有的识别方面的内容，都还处于比较前沿的状态，在实际应用中主要还是B端场景，C端使用的相对较少。Oculus Quest 上近期刚推出了手势识别的接口，预计后面会有越来越多的C端应用尝试这种新的交互方式。

#### 应用端

##### 数字内容

> 参考记录模块：[Animation](https://metal-j.github.io/animation/2021/10/12/Animation_Intro.html)

- 最常见的**VR游戏应用开发**，它在技术层面跟普通的3D游戏没有什么区别，大都是使用**U3D/UE**等引擎来开发。所以未来想从事VR内容开发的同学，可以直接从游戏引擎入手即可。另一个方向是**神经渲染、数字孪生、SLAM、3DCV**等。

##### 视频制作

VR视频的制作目前都有比较成熟设备。用户在使用时都免去了早期还需要拼接处理的步骤，直接输出360度全景视频。制作是简单了，但是视频领域仍然有两个新技术需要探索：**视频分片编解码**和**容积摄影**。

- **视频分片编解码** 可以解决两个难题：**带宽不够**以及**芯片解码限制**。未来为了能够传输和播放12K的视频，需要我们能在编解码环节进行优化。目前已经有一些公司在这个方向投入。比如VR4P、VSBIT、威尔云等。
- **容积摄影技术** 它主要是通过多摄像头从多个角度拍摄同一个场景，最终“拼”出一个人可以“走进去”的3D的视频场景，实现这一点也需要一些图像处理的知识。现在拍的VR电影绝大多数都是固定视角的全景相机拍的，所以看的时候也只能固定一个视角。现在也有叫做**体三维摄影**的技术，是超多相机多视角拍摄，完全复原场景。这种情况下，观众可以在"视频"里自由移动。

##### 网络与互联网

- **云VR**会是VR领域的一个大趋势，它需要在云端服务器对应用的显示进行编码，然后传到本地。（**混合云？部分内容是用云实时传输，比如微软飞行模拟器**）
- 另外，未来将大行其道的虚拟社交（**全真互联网**），对网络传输要求也会比较高，形象同步需要传输的数据量跟传统网游比大了一个量级。千人同服，还需要在数据同步方面做很多研究。

##### 区块链经济系统

> 参考记录模块：[区块链](https://metal-j.github.io/blockchain/2021/09/29/Blockchain_Intro.html)

- **区块链**。因为虚拟世界中的**经济系统**可以跟现实世界打通，虚拟世界中会有新的经济体出现，你在虚拟世界中，可以得到一份真正可以养家糊口的工作。比如，虚拟世界场景建筑师，或者虚拟世界中的一个互动演员。